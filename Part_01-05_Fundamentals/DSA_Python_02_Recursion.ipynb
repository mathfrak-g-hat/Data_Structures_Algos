{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10de5546-3759-4fc4-84e9-2b28cdd69620",
   "metadata": {},
   "source": [
    "# Data Structures and Algorithms in Python - Ch.4: Recursion\n",
    "### AJ Zerouali, 2023/09/14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f0e53a-9a6a-47cf-a48c-9c137f1975eb",
   "metadata": {},
   "source": [
    "## 0) Introduction\n",
    "\n",
    "Linked lists were one of the last chapters in my first programming course in 2007. In 2010, I failed an interview at Ubisoft because I forgot everything I knew about this data structure. I hereby pledge to take my revenge against linked lists in these notes.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- Chapter 4 of \"Data structures and algorithms in Python\", by Goodrich, Tamassia and Goldwasser (primary, abbreviated [GTG13]). \n",
    "- Section 15 of \"Python for Data Structures, Algorithms, and Interviews!\" by Jose Portilla.\n",
    "\n",
    "**Comments on Portilla's course:**\n",
    "- Covers 3 topics: Recursion in general, recursion, and dynamic programming. Tail recursion alluded to in Lecture 105 (last in section 15).\n",
    "- Memoization has to do with caching results, and doesn't seem to be covered in [GTG13].\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5eddd-3a0d-42a0-aedf-1da4f1e26cb6",
   "metadata": {},
   "source": [
    "## 1) Basic examples of recursion.\n",
    "\n",
    "Some basic examples to illustrate the concepts. See the homework problems in the exercises notebook for more.\n",
    "\n",
    "In the programming context, a recursive function is one that calls itself recursively. For this process to stop at some point, one needs a base case that will typically be the last call of the function to itself. As one might expect, this is a CS counterpart of induction in the mathematical sense.\n",
    "\n",
    "A useful implementation trick is to remember that the *return* line always involves the recursive function, and this is always a good starting point to decide how to set up the induction and the base case.\n",
    "\n",
    "**Comment:** Recursion seems to be used to get rid of certain loops. Does that indeed improve the time complexity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea65fd-473b-4c60-907b-ea539727150e",
   "metadata": {},
   "source": [
    "### 1.a - The factorial\n",
    "\n",
    "This is the most elementary and illustrative example. In a first programming course, the factorial example is used to teach loops. In data structures and algorithms, it is used to illustrate the idea of a function calling itself recursively.\n",
    "\n",
    "Since $n! = n\\cdot (n-1)!$ for $n>0$, our factorial function could simply return:\n",
    "\n",
    "        def factorial(n):\n",
    "            ...\n",
    "            return n*factorial(n-1)\n",
    "\n",
    "The question now is to stop this chain of calls with the base case of $0!=1$. The recursive implementation of the factorial is therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a843d572-8a97-4911-8da2-7d6bb0ca1452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n*factorial(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dfdf099-655c-4460-8e42-5b68d677f16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec5a6c-9318-4b47-be3d-dd89e043e78b",
   "metadata": {},
   "source": [
    "### 1.b - Binary search revisited\n",
    "\n",
    "We discussed binary search in section 2.b of part 1 (Algo_Analysis). Instead of relying on a while loop, we could nest the function calls each time we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61d4efd-87bc-4c60-9583-490a32c57ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(arr, target, low = 0, high = None):\n",
    "    '''\n",
    "        Recursive implementation of binary search.\n",
    "        :param arr: sorted list of numbers\n",
    "        :param target: target value to find in arr.\n",
    "        :param low: lower-bound index for search. 0 by default.\n",
    "        :param high: upper-bound index. None by default. \n",
    "        :return: index of target in arr if search is successful and False otherwise.\n",
    "    '''\n",
    "    if not high:\n",
    "        high = len(arr)-1\n",
    "    if high < low:\n",
    "        return False\n",
    "    else:\n",
    "        mid = (high+low)//2\n",
    "        if target == arr[mid]:\n",
    "            return mid\n",
    "        elif target > arr[mid]:\n",
    "            return binary_search(arr, target, mid + 1, high)\n",
    "        elif target < arr[mid]:\n",
    "            return binary_search(arr, target, low, mid -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c577471-3bf1-432e-9438-e0c061963206",
   "metadata": {},
   "source": [
    "## 2) Memoization (intro to dynamic programming)\n",
    "\n",
    "Portilla devoted two interview exercises to memoization/dynamic programming. \n",
    "\n",
    "Dynamic programming, in the context of DSA is an algorithm that divides the general problem into similar subproblems, and builds upon the latter to compute the solution of the main problem. This is not exactly the same as the optimal control and reinforcement learning concept of dynamic programming (which is about policy evaluation and then policy improvement). This topic is addressed in section 13.3 of [GTG13], in the context of text processing.\n",
    "\n",
    "Memoization, is about using a cache or a lookup table when solving a problem. Portilla doesn't give a formal lecture about this topic, and redirects to the Wikipedia page:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Memoization\n",
    "\n",
    "As this is only an overview of the topic of memoization/dynamic, I will just provide basic examples of how this is implemented without much depth (for now)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789c7e5-8f59-41aa-95d8-5c252d8b3811",
   "metadata": {},
   "source": [
    "### 2.a - Example: The factorial function\n",
    "\n",
    "We gave a recursive implementation of the factorial function. Here we will use a cache to store previously computed results. We take this from the Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eddad3f-a99b-4ab5-b46e-e06f46278b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n, cache = None):\n",
    "    if cache==None or len(cache)<n:\n",
    "        cache = [1]+ [None]*n\n",
    "    if n==0:\n",
    "        return cache[n]\n",
    "    elif cache[n]!=None:\n",
    "        return cache[n]\n",
    "    else:\n",
    "        x = factorial(n-1, cache)*n\n",
    "        cache[n]=x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "919c50ae-c26f-4a35-a7cd-3c1ef73eaac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "132355a5-1cdd-45a5-8177-5495a3d35c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11d9df6-d822-4c57-a4cf-7873ebdc42c5",
   "metadata": {},
   "source": [
    "### 2.b - Some remarks\n",
    "\n",
    "Dynamic programming is a popular topic for tech interviews, and deserves its own section. [GTG13] discusses it rather late, in section 4.3, after having discussed trees and divide-and-conquer algorithms. Portilla mentions this topic only in passing, and provides the coin change problem as an illustration. In Karimov's DSA course, dynamic programming is also covered rather late, in sections 47 and 48. In conclusion, I will not write more about this topic in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aeab60-dd5a-4f2a-8fdf-aa31c7d6a9c4",
   "metadata": {},
   "source": [
    "## 3) Analyzing the running time of recursions\n",
    "\n",
    "This is based on section 4.2 of [GTG13]. Before giving some concrete examples of how running times are analyzed in this context, we introduce some CS vocabulary ([GTG13] p.161):\n",
    "- By an **activation** of the recursive function, we mean a particular *invocation* of this function.\n",
    "- By **tracing a recursion** we mean chasing the diagram of calls/activations for a given input size *n*.\n",
    "\n",
    "**Comment:** Finding the definition of \"trace\" is precisely what I have always abhorred about CS and engineering: the use of terms with no accurate definition and the lack of good communication practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adc80a-c048-49c1-a2a4-e45e456b79a3",
   "metadata": {},
   "source": [
    "### 3.a - Example: The factorial function\n",
    "\n",
    "It is easy to see in the example of section 1.a that:\n",
    "1) The call *factorial(n)* will entail $(n+1)$ activations of the function.\n",
    "2) For each individual activation of *factorial(k)*, the body executes a constant number of operations.\n",
    "3) From the above, the $(n+1)$ activations of $O(1)$ complexity lead to an $O(n)$ running time for *factorial(n)*.\n",
    "\n",
    "### 3.a - Example: Binary search\n",
    "\n",
    "In this case (see section 1.b), we again have an $O(1)$ running time for each activation. It remains to determine the number of activations for a given $n$, in the worst case scenario where the target value lies at one of the endpoints of the array. Since at each activation we are dividing the length of the sorted array by at least 2, the number of activations $k$ required to reach the final length of $1$ must satisfy $n=2^k$, so that $k=\\log_2(n)$. This gives us the $O(\\log(n))$ complexity of recursive binary search.\n",
    "\n",
    "**Comments:** [GTG13] analyze more examples in section 4.2, and mention *amortization* (sec.5.3) and *tree traversal* (Ch.8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5581a14-3d09-4371-97b5-d3e1d19b39f9",
   "metadata": {},
   "source": [
    "## 4) Issues with recursion\n",
    "\n",
    "See section 4.3 of [GTG13]. The main takeaway of this section is that algorithms based on recursion can easily end-up having exponential running times. The first case they discuss is the element uniqueness problem of section 3.3.3, which we skip here.\n",
    "\n",
    "An important example of exponential execution time with recursion is a bad implementation of Fibonacci sequence computation (see Ex.3 in the exercises notebook). Suppose we use the following function to compute the $n$-th Fibonacci number $F_n$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c1067-b2a0-4668-98db-1e2b664b42d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib_rec(n):\n",
    "    if n==0:\n",
    "        return 0\n",
    "    elif n==1:\n",
    "        return 1\n",
    "    elif n>1:\n",
    "        return fib_rec(n-1)+fib_rec(n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab7f3f-c096-4e40-8004-54ef7e059f30",
   "metadata": {},
   "source": [
    "We have two issues with this implementation. The first one, which is more obvious, is that we are repeating a substantial number of elementary computations when we call *fib_rec(n-1)+fib_rec(n-2)* at each step. \n",
    "\n",
    "The second issue, which is far more concerning, is the rate of growth of the terms, meaning that the number of calls more than doubles at each activation of *fib_rec()*. To see this fact, notice first that $F_n>2^{\\frac{n}{2}}$ for all $n\\ge 4$. As such, we can infer that computing $F_n$ for a large number is $\\Theta(2^{n/2})$, since it is based on additions.\n",
    "\n",
    "With a usual for loop, computing $F_{50}$ takes around $5\\cdot10^{-5}s$ to compute, while *fib_rec(50)* takes more than $10min$ (in fact it freezes the Python kernel for Jupyter at some point).\n",
    "\n",
    "The correct recursive implementation of a function that computes the $n$-th term of the Fibonacci sequence is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95851681-d397-4200-9391-6a4fedad9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci(n):\n",
    "    if n<=1:\n",
    "        return (1, 0)\n",
    "    else:\n",
    "        (a,b)=fibonacci(n-1)\n",
    "        return (a+b, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c328a9-cdc1-4e7d-8a32-07512399203d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5426139-e7aa-4564-bdaa-7a072e36456e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
